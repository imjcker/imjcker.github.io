---
layout: post
title: Hadoop 搭建
category: 大数据
tags: bigdata Hadoop 
bg: 2020/hadoop.png
---

hadoop 安装配置



## 本地安装版



## 伪分布式



## 分布式

解压拷贝到`/usr/local/hadoop`

hadoop 环境变量

```shell
echo "export HADOOP_HOME=/usr/local/hadoop" >> /etc/profile
echo "export PATH=$PATH:$HADOOP_HOME/sbin:$HADOOP_HOME/bin" >> /etc/profile
echo "export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop" >> /etc/profile
source /etc/profile


export HDFS_NAMENODE_USER=root
export HDFS_DATANODE_USER=root
export HDFS_SECONDARYNAMENODE_USER=root
export YARN_RESOURCEMANAGER_USER=root
export YARN_NODEMANAGER_USER=root
```



修改Hadoop、mapreduce、yarn配置的JDK

### 配置

#### core-site.xml

配置core-site.xml

```xml
<configuration>
 <property>
   <name>fs.defaultFS</name>
   <value>hdfs://hadoop-m:9000</value>
 </property>
 <property>
   <name>hadoop.tmp.dir</name>
   <value>/usr/local/hadoop/data/tmp</value>
 </property>
</configuration>
```

#### hdfs-site.xml

配置hdfs-site.xml

```xml
<property>
  <name>dfs.replication</name>
  <value>3</value>
</property>
<property>
  <name>dfs.name.dir</name>
  <value>/usr/local/hadoop/data/name</value>
</property>
<property>
  <name>dfs.data.dir</name>
  <value>/usr/local/hadoop/data/data</value>
</property>
```

#### mapred-site.xml

```xml
<property>
  <name>mapreduce.framework.name</name>
  <value>yarn</value>
</property>
<property>
  <name>mapreduce.application.classpath</name>
  <value>$HADOOP_HOME/share/hadoop/mapreduce/*:$HADOOP_HOME/share/hadoop/mapreduce/lib/*       </value>
</property>
```

#### yarn-site.xml

```xml
<configuration>
    <property>
        <name>yarn.nodemanager.aux-services</name>
        <value>mapreduce_shuffle</value>
    </property>
    <property>
            <name>yarn.resourcemanager.hostname</name>
            <value>hadoop-m</value>
    </property>
    <property>
        <name>yarn.nodemanager.env-whitelist</name>
      <value>JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_HOME</value>
    </property>
</configuration>
```







配置workers

```
hadoop-m
hadoop-s1
hadoop-s2
hadoop-s3
```

